<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.29">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Kevin Markham">
<meta name="description" content="A practical guide to help you transition from Machine Learning novice to skilled Machine Learning practitioner.">

<title>18&nbsp; Class imbalance – Master Machine Learning with scikit-learn</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./ch19.html" rel="next">
<link href="./ch17.html" rel="prev">
<link href="./favicon.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-0815c480559380816a4d1ea211a47e91.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-e32d5626311174d9f6538aca58dc36c7.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://cdn.usefathom.com/script.js" data-site="AWKMQOCB" defer=""></script>


<meta property="og:title" content="18&nbsp; Class imbalance – Master Machine Learning with scikit-learn">
<meta property="og:description" content="">
<meta property="og:image" content="https://mlbook.dataschool.io/ch18_files/figure-html/cell-13-output-1.png">
<meta property="og:site_name" content="Master Machine Learning with scikit-learn">
<meta property="og:image:height" content="858">
<meta property="og:image:width" content="1025">
<meta name="twitter:title" content="18&nbsp; Class imbalance – Master Machine Learning with scikit-learn">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="https://mlbook.dataschool.io/ch18_files/figure-html/cell-13-output-1.png">
<meta name="twitter:image-height" content="858">
<meta name="twitter:image-width" content="1025">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./ch18.html"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Class imbalance</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Master Machine Learning with scikit-learn</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About this book</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Review of the Machine Learning workflow</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Encoding categorical features</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Improving your workflow with ColumnTransformer and Pipeline</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Workflow review #1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Encoding text data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Handling missing values</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Fixing common workflow problems</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Workflow review #2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Evaluating and tuning a Pipeline</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Comparing linear and non-linear models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Ensembling multiple models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Feature selection</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch14.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Feature standardization</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch15.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Feature engineering with custom transformers</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch16.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Workflow review #3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch17.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">High-cardinality categorical features</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch18.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Class imbalance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch19.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Class imbalance walkthrough</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch20.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Going further</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction-to-class-imbalance" id="toc-introduction-to-class-imbalance" class="nav-link active" data-scroll-target="#introduction-to-class-imbalance"><span class="header-section-number">18.1</span> Introduction to class imbalance</a></li>
  <li><a href="#preparing-the-mammography-dataset" id="toc-preparing-the-mammography-dataset" class="nav-link" data-scroll-target="#preparing-the-mammography-dataset"><span class="header-section-number">18.2</span> Preparing the mammography dataset</a></li>
  <li><a href="#sec-18-3" id="toc-sec-18-3" class="nav-link" data-scroll-target="#sec-18-3"><span class="header-section-number">18.3</span> Evaluating a model with train/test split</a></li>
  <li><a href="#exploring-the-results-with-a-confusion-matrix" id="toc-exploring-the-results-with-a-confusion-matrix" class="nav-link" data-scroll-target="#exploring-the-results-with-a-confusion-matrix"><span class="header-section-number">18.4</span> Exploring the results with a confusion matrix</a></li>
  <li><a href="#calculating-rates-from-a-confusion-matrix" id="toc-calculating-rates-from-a-confusion-matrix" class="nav-link" data-scroll-target="#calculating-rates-from-a-confusion-matrix"><span class="header-section-number">18.5</span> Calculating rates from a confusion matrix</a></li>
  <li><a href="#using-auc-as-the-evaluation-metric" id="toc-using-auc-as-the-evaluation-metric" class="nav-link" data-scroll-target="#using-auc-as-the-evaluation-metric"><span class="header-section-number">18.6</span> Using AUC as the evaluation metric</a></li>
  <li><a href="#cost-sensitive-learning" id="toc-cost-sensitive-learning" class="nav-link" data-scroll-target="#cost-sensitive-learning"><span class="header-section-number">18.7</span> Cost-sensitive learning</a></li>
  <li><a href="#sec-18-8" id="toc-sec-18-8" class="nav-link" data-scroll-target="#sec-18-8"><span class="header-section-number">18.8</span> Tuning the decision threshold</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Class imbalance</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduction-to-class-imbalance" class="level2" data-number="18.1">
<h2 data-number="18.1" class="anchored" data-anchor-id="introduction-to-class-imbalance"><span class="header-section-number">18.1</span> Introduction to class imbalance</h2>
<p>One of the common issues you might run into when working on a classification problem is known as “class imbalance”. This refers to a situation in which the classes are not equally represented in the dataset.</p>
<p>Class imbalance is inherent to many domains. For example, if we were classifying fraudulent transactions in a credit card dataset, there would naturally be class imbalance since the vast majority of transactions are not going to be fraudulent.</p>
<p>Class imbalance can occur in both binary classification problems, meaning there are 2 classes, and multiclass problems, meaning there are more than 2 classes. In binary classification, the class that has more samples is called the “majority class”, and the class that has fewer samples is called the “minority class”.</p>
<p>So why does class imbalance even matter? In brief, Machine Learning models often have a harder time predicting the minority class because there are fewer examples of this class to learn from. In other words, your model won’t be able to learn as much about the patterns in the minority class, and thus it may have a hard time differentiating between the classes.</p>
<p>Keep in mind that some class imbalance is present in most datasets. For example, in our Titanic dataset, the majority class represents 62% of the samples, and the minority class represents 38% of the samples. There’s even more imbalance in the census dataset, with a split of 76% to 24%.</p>
<p>A small amount of class imbalance (like in the Titanic dataset) tends not to matter, and you should just use all of the usual techniques that you’ve learned in this book. But as the amount of class imbalance increases, more specialized techniques need to be applied to the problem, and those techniques are the focus of this chapter.</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>Overview of class imbalance:</strong></p>
<ul>
<li>“Class imbalance” is when classes are not equally represented</li>
<li>Inherent to many domains</li>
<li>Can occur in binary and multiclass problems</li>
<li>Binary problems have a “majority class” and a “minority class”</li>
<li>Makes it harder for the model to learn patterns in the minority class</li>
<li>Most datasets have some class imbalance</li>
<li>Greater class imbalance requires more specialized techniques</li>
</ul>
</div>
</div>
</div>
<div id="bcd5cc4b" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>y.value_counts(normalize<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>0    0.616162
1    0.383838
Name: Survived, dtype: float64</code></pre>
</div>
</div>
<div id="0b73bc15" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>census_y.value_counts(normalize<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code> &lt;=50K    0.760718
 &gt;50K     0.239282
Name: class, dtype: float64</code></pre>
</div>
</div>
</section>
<section id="preparing-the-mammography-dataset" class="level2" data-number="18.2">
<h2 data-number="18.2" class="anchored" data-anchor-id="preparing-the-mammography-dataset"><span class="header-section-number">18.2</span> Preparing the mammography dataset</h2>
<p>For this chapter, we’re going to use a dataset of mammography scans that were designed to detect the presence of cancer.</p>
<p>We’ll read in the dataset using pandas. You can see that there are 6 features as well as a target column called “class”. Each sample represents an object of interest that was extracted from a scan, and each object was translated into these features using a computer vision algorithm.</p>
<p>The class column has two possible values, -1 and 1. -1 means the object did not indicate the presence of cancer, and 1 means the object did indicate the presence of cancer. These labels were assigned by a human expert and thus represent the “ground truth” labels for the dataset.</p>
<div id="5870457c" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>scan <span class="op">=</span> pd.read_csv(<span class="st">'http://bit.ly/scanrecords'</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>scan.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">attr1</th>
<th data-quarto-table-cell-role="th">attr2</th>
<th data-quarto-table-cell-role="th">attr3</th>
<th data-quarto-table-cell-role="th">attr4</th>
<th data-quarto-table-cell-role="th">attr5</th>
<th data-quarto-table-cell-role="th">attr6</th>
<th data-quarto-table-cell-role="th">class</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.230020</td>
<td>5.072578</td>
<td>-0.276061</td>
<td>0.832444</td>
<td>-0.377866</td>
<td>0.480322</td>
<td>'-1'</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.155491</td>
<td>-0.169390</td>
<td>0.670652</td>
<td>-0.859553</td>
<td>-0.377866</td>
<td>-0.945723</td>
<td>'-1'</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>-0.784415</td>
<td>-0.443654</td>
<td>5.674705</td>
<td>-0.859553</td>
<td>-0.377866</td>
<td>-0.945723</td>
<td>'-1'</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.546088</td>
<td>0.131415</td>
<td>-0.456387</td>
<td>-0.859553</td>
<td>-0.377866</td>
<td>-0.945723</td>
<td>'-1'</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-0.102987</td>
<td>-0.394994</td>
<td>-0.140816</td>
<td>0.979703</td>
<td>-0.377866</td>
<td>1.013566</td>
<td>'-1'</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>As you can see, -1 (meaning “non-cancerous”) is the majority class, and 1 (meaning “cancerous”) is the minority class. You might call this severe class imbalance because the minority class makes up only 2% of the dataset.</p>
<div id="3646589f" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>scan[<span class="st">'class'</span>].value_counts(normalize<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>'-1'    0.97675
'1'     0.02325
Name: class, dtype: float64</code></pre>
</div>
</div>
<p>Although scikit-learn doesn’t require it, we’re going to map the strings in the class column to the integers 0 and 1, in which 0 means “non-cancerous” and 1 means “cancerous”.</p>
<div id="e3066d5a" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>scan[<span class="st">'class'</span>] <span class="op">=</span> scan[<span class="st">'class'</span>].<span class="bu">map</span>({<span class="st">"'-1'"</span>:<span class="dv">0</span>, <span class="st">"'1'"</span>:<span class="dv">1</span>})</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>scan.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">attr1</th>
<th data-quarto-table-cell-role="th">attr2</th>
<th data-quarto-table-cell-role="th">attr3</th>
<th data-quarto-table-cell-role="th">attr4</th>
<th data-quarto-table-cell-role="th">attr5</th>
<th data-quarto-table-cell-role="th">attr6</th>
<th data-quarto-table-cell-role="th">class</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.230020</td>
<td>5.072578</td>
<td>-0.276061</td>
<td>0.832444</td>
<td>-0.377866</td>
<td>0.480322</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.155491</td>
<td>-0.169390</td>
<td>0.670652</td>
<td>-0.859553</td>
<td>-0.377866</td>
<td>-0.945723</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>-0.784415</td>
<td>-0.443654</td>
<td>5.674705</td>
<td>-0.859553</td>
<td>-0.377866</td>
<td>-0.945723</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.546088</td>
<td>0.131415</td>
<td>-0.456387</td>
<td>-0.859553</td>
<td>-0.377866</td>
<td>-0.945723</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-0.102987</td>
<td>-0.394994</td>
<td>-0.140816</td>
<td>0.979703</td>
<td>-0.377866</td>
<td>1.013566</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Now that the dataset is ready, we’re going to define two objects, <code>scan_X</code> and <code>scan_y</code>, to represent the feature matrix and the target.</p>
<div id="1ce65ea6" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>scan_X <span class="op">=</span> scan.drop(<span class="st">'class'</span>, axis<span class="op">=</span><span class="st">'columns'</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>scan_y <span class="op">=</span> scan[<span class="st">'class'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="sec-18-3" class="level2" data-number="18.3">
<h2 data-number="18.3" class="anchored" data-anchor-id="sec-18-3"><span class="header-section-number">18.3</span> Evaluating a model with train/test split</h2>
<p>Throughout the book, we’ve been using cross-validation as the model evaluation procedure. But in this chapter, we’re going to use train/test split instead, since that will help you to better understand the metrics and techniques I’ll be outlining. However, I’ll return to cross-validation in chapter 19.</p>
<p>Before I get into the code, here’s a quick overview of how we use train/test split for model evaluation:</p>
<ol type="1">
<li>You split the dataset into training and testing sets.</li>
<li>You fit the model on the training set.</li>
<li>You use the fitted model to make predictions on the testing set and evaluate those predictions.</li>
</ol>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>Steps of train/test split:</strong></p>
<ol type="1">
<li>Split rows into training and testing sets</li>
<li>Train model on training set</li>
<li>Make predictions on testing set</li>
<li>Evaluate predictions</li>
</ol>
</div>
</div>
</div>
<p>When we use K-fold cross-validation, we’re really just running train/test split K times in a very systematic way and then averaging the results. Cross-validation is superior because it outputs a lower variance estimate of model performance, but again, we’re going to start with train/test split to help you better understand the concepts in this chapter.</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>Cross-validation vs train/test split:</strong></p>
<ul>
<li>Cross-validation is just repeated train/test split</li>
<li>Cross-validation outputs a lower variance estimate of performance</li>
</ul>
</div>
</div>
</div>
<p>Anyway, let’s start by splitting the dataset into training and testing sets. We’ll use a split of 75% of the rows for training and 25% of the rows for testing, and we’ll set a <code>random_state</code> for reproducibility.</p>
<div id="5b39baf5" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(scan_X, scan_y,</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>                                                    test_size<span class="op">=</span><span class="fl">0.25</span>,</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>                                                    random_state<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>                                                    stratify<span class="op">=</span>scan_y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We’ll use stratified sampling so that the class proportions will be approximately equal in the training and testing sets. This is especially important when you have severe class imbalance, otherwise you might have insufficient examples of the minority class in either the training or testing set.</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>Stratified sampling:</strong></p>
<ul>
<li>Ensures that each set is representative of the dataset</li>
<li>Especially important when there is severe class imbalance</li>
</ul>
</div>
</div>
</div>
<p>Now we’ll fit our logistic regression model on the training set, and use the fitted model to make predictions on the testing set. The <code>predict</code> method outputs class predictions of 0 or 1, which we’ll store as <code>y_pred</code>.</p>
<p>As an aside, we’re not using a <code>Pipeline</code> here because the features are entirely numeric and don’t need any preprocessing. However, if you were using a <code>Pipeline</code>, you would just use <code>pipe.fit</code> and <code>pipe.predict</code> instead.</p>
<div id="11f44fe3" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>logreg.fit(X_train, y_train)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> logreg.predict(X_test)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>y_pred</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>array([0, 0, 0, ..., 0, 0, 0])</code></pre>
</div>
</div>
<p>Finally, let’s evaluate the model’s predictions. We’ve used accuracy as our evaluation metric throughout the book, so we’ll try that here. We have to import the <code>accuracy_score</code> function from the <code>metrics</code> module, and then we pass it the true values followed by the predicted values.</p>
<p>It outputs an accuracy of 98%, which sounds great. But as you might recall, about 98% of the target values are 0, so an uninformed model could achieve 98% accuracy by always predicting class 0.</p>
<p>Because the accuracy value isn’t telling us much about how the model is actually performing, it’s not a particularly useful evaluation metric in cases of severe class imbalance.</p>
<div id="5be1a9a3" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>accuracy_score(y_test, y_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>0.9831902718168812</code></pre>
</div>
</div>
</section>
<section id="exploring-the-results-with-a-confusion-matrix" class="level2" data-number="18.4">
<h2 data-number="18.4" class="anchored" data-anchor-id="exploring-the-results-with-a-confusion-matrix"><span class="header-section-number">18.4</span> Exploring the results with a confusion matrix</h2>
<p>Before we choose an evaluation metric other than accuracy, let’s first use a confusion matrix to get a better understanding of our results.</p>
<p>We import it from the <code>metrics</code> module, and then pass it the true values followed by the predicted values. Note that the ordering is important, because your confusion matrix will be incorrect if you pass the predicted values first and the true values second.</p>
<div id="9c6978c0" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>confusion_matrix(y_test, y_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>array([[2721,   10],
       [  37,   28]])</code></pre>
</div>
</div>
<p>It can be hard to remember what each of the four boxes represents, so a nice alternative is to use the <code>plot_confusion_matrix</code> function, which was introduced in version 0.22. After importing it, we pass it a fitted model, <code>X_test</code>, and <code>y_test</code>. It makes predictions for <code>X_test</code>, and outputs a confusion matrix by comparing the results to <code>y_test</code>. In other words, it duplicates some of the work we’ve already done, though it ends up with the same result.</p>
<p>As an aside, scikit-learn 1.0 actually provides a different method for plotting a confusion matrix that allows you to directly pass in <code>y_pred</code>.</p>
<p>Anyway, the confusion matrix is now labeled, with the true labels as the rows and the predicted labels as the columns. You can see that:</p>
<ul>
<li>In 2721 cases, the model predicted 0 and that was correct. These are called True Negatives.</li>
<li>In 28 cases, it predicted 1 and that was correct. These are True Positives.</li>
<li>In 37 cases, it predicted 0 and that was incorrect. These are False Negatives.</li>
<li>And in 10 cases, it predicted 1 and that was incorrect. These are False Positives.</li>
</ul>
<div id="df711f7c" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> plot_confusion_matrix</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>disp <span class="op">=</span> plot_confusion_matrix(logreg, X_test, y_test, cmap<span class="op">=</span><span class="st">'Blues'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ch18_files/figure-html/cell-13-output-1.png" width="513" height="429" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">&nbsp;</th>
<th style="text-align: center;">Predicted 0</th>
<th style="text-align: center;">Predicted 1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>True label 0</strong></td>
<td style="text-align: center;">True Negatives</td>
<td style="text-align: center;">False Positives</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>True label 1</strong></td>
<td style="text-align: center;">False Negatives</td>
<td style="text-align: center;">True Positives</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>You can see that the confusion matrix helps us understand the performance of our classifier much better than the accuracy score.</p>
<p>In particular, it highlights a troubling issue, which we can see by examining the bottom row. There were 65 samples in which cancer was present in the testing set, and it was only detected in 28 of those cases. Given the context, in which the model is attempting to detect the presence of cancer, you could imagine that it would be highly problematic to miss 37 out of 65 cases. This is an issue that we will address by the end of this chapter.</p>
</section>
<section id="calculating-rates-from-a-confusion-matrix" class="level2" data-number="18.5">
<h2 data-number="18.5" class="anchored" data-anchor-id="calculating-rates-from-a-confusion-matrix"><span class="header-section-number">18.5</span> Calculating rates from a confusion matrix</h2>
<p>Before we discuss a solution to the problem from the previous lesson, let’s first calculate a few rates from the confusion matrix to help us quantify what we want to improve and what tradeoffs we’ll be making. Here’s our confusion matrix from the previous lesson.</p>
<div id="ff963ba4" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>confusion_matrix(y_test, y_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>array([[2721,   10],
       [  37,   28]])</code></pre>
</div>
</div>
<p>True Positive Rate answers the question: When cancer is present, how often is that correctly predicted? We divide the True Positives by the entire bottom row, and we get 43.1%. True Positive Rate is also known as recall.</p>
<div id="3f595fc6" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="dv">28</span> <span class="op">/</span> (<span class="dv">37</span> <span class="op">+</span> <span class="dv">28</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>0.4307692307692308</code></pre>
</div>
</div>
<p>True Negative Rate answers the question: When cancer is not present, how often is that correctly predicted? We divide the True Negatives by the entire top row, and we get 99.6%.</p>
<div id="e0f2449b" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2721</span> <span class="op">/</span> (<span class="dv">2721</span> <span class="op">+</span> <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>0.9963383376052728</code></pre>
</div>
</div>
<p>False Positive Rate answers the question: When cancer is not present, how often is that incorrectly predicted? We divide the False Positives by the entire top row, and we get 0.4%. As you might have figured out, the False Positive Rate is 1 minus the True Negative Rate.</p>
<div id="84d7ca86" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="dv">10</span> <span class="op">/</span> (<span class="dv">2721</span> <span class="op">+</span> <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>0.003661662394727206</code></pre>
</div>
</div>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>Calculated rates:</strong></p>
<ul>
<li><strong>True Positive Rate:</strong> 0.431
<ul>
<li>Recall for class 1</li>
</ul></li>
<li><strong>True Negative Rate:</strong> 0.996
<ul>
<li>Recall for class 0</li>
</ul></li>
<li><strong>False Positive Rate:</strong> 0.004
<ul>
<li>1 minus True Negative Rate</li>
</ul></li>
</ul>
</div>
</div>
</div>
<p>Another way to see these results without doing the calculations yourself is with the classification report. We import it and pass it the true and predicted values.</p>
<ul>
<li>The True Positive Rate is the recall for class 1, which is 43%.</li>
<li>The True Negative Rate is the recall for class 0, which has been rounded to 100%.</li>
<li>The False Positive Rate is not directly shown, but it’s 1 minus the True Negative Rate, thus it’s close to 0%.</li>
<li>The overall accuracy is also shown, which is 98%, though that’s not our focus here.</li>
</ul>
<div id="97cfb39f" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

           0       0.99      1.00      0.99      2731
           1       0.74      0.43      0.54        65

    accuracy                           0.98      2796
   macro avg       0.86      0.71      0.77      2796
weighted avg       0.98      0.98      0.98      2796
</code></pre>
</div>
</div>
<p>Because the True Positive Rate of 43% seems quite problematic, you might think that the solution is just to work on maximizing True Positive Rate. However, the danger of only focusing on True Positive Rate is that you might end up with a confusion matrix similar to this.</p>
<div id="3f28b1a7" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>confusion_matrix(y_test, np.ones_like(y_pred))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>array([[   0, 2731],
       [   0,   65]])</code></pre>
</div>
</div>
<p>The True Positive Rate in this case is 100%, but that’s because we’re always predicting the positive class. As such, the False Positive Rate would also be 100%. I think you would agree that this is not a useful solution.</p>
</section>
<section id="using-auc-as-the-evaluation-metric" class="level2" data-number="18.6">
<h2 data-number="18.6" class="anchored" data-anchor-id="using-auc-as-the-evaluation-metric"><span class="header-section-number">18.6</span> Using AUC as the evaluation metric</h2>
<p>Now that I’ve gone through the nature of the problem, let’s start talking about a solution.</p>
<p>The first part of the solution is to choose a different evaluation metric to focus on when tuning our model. We’re going to use AUC, which is short for Area Under the ROC Curve. At a high level, AUC is a measure of how well the model separates the classes by predicting higher probabilities for the class 1 samples than for the class 0 samples.</p>
<p>To explain this further, let’s have the fitted model output predicted probabilities (rather than class predictions) by using the <code>predict_proba</code> method. We’ll store these in <code>y_score</code> and print them out.</p>
<p>This first number tells us that for the first sample in the test set, the model predicts a 0.18% likelihood that it belongs to the positive class. The second number tells us that for the second sample in the test set, the model predicts a 0.26% likelihood that it belongs to the positive class. And so on.</p>
<div id="159a99c1" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>y_score <span class="op">=</span> logreg.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>y_score</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>array([0.00179856, 0.00255211, 0.00181612, ..., 0.0015053 , 0.02641707,
       0.00073432])</code></pre>
</div>
</div>
<p>AUC is a measure of how good a job the model is doing at assigning higher probabilities to class 1 samples than class 0 samples. In other words, AUC doesn’t care about the actual predicted probability values, rather it cares only about the rank ordering of the values. As such, it can be used with any classifier that outputs predicted probabilities, regardless of whether those probabilities are well-calibrated.</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>Area Under the ROC Curve (AUC):</strong></p>
<ul>
<li>Measures how well the model separates the classes</li>
<li>Wants the model to assign higher probabilites to class 1 samples than class 0 samples</li>
<li>Can be used with any classifier that outputs predicted probabilities</li>
</ul>
</div>
</div>
</div>
<p>Let’s actually calculate the AUC for our model. We import the <code>roc_auc_score</code> function, and then we pass it the true values followed by the predicted probabilities, not the class predictions. It outputs an AUC of 0.93, which is quite good.</p>
<div id="f3e56e3f" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>roc_auc_score(y_test, y_score)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>0.9339323437455991</code></pre>
</div>
</div>
<p>To put this in context, a perfect model would achieve an AUC of 1.0, whereas a completely uninformed model would achieve an AUC of 0.5.</p>
<p>A more formal way to interpret this value is as follows: If you randomly chose a class 1 sample and you randomly chose a class 0 sample, there’s a 93% probability that the model assigned a higher predicted probability to the class 1 sample than the class 0 sample.</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>AUC scores:</strong></p>
<ul>
<li><strong>Perfect model:</strong> 1.0</li>
<li><strong>Uninformed model:</strong> 0.5</li>
</ul>
</div>
</div>
</div>
<p>A natural follow-up question might be: Why is the AUC so high, when the True Positive Rate is so low?</p>
<p>To answer that question, we have to talk about the decision threshold. The decision threshold is the predicted probability value above which a model will predict the positive class. By default, the threshold is 0.5, which means that if a model predicts a probability of 0.7, it predicts class 1. Whereas if a model predicts a probability of 0.2, it predicts class 0.</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>Decision threshold:</strong></p>
<ul>
<li>Predicted probability value above which a model will predict the positive class</li>
<li>Default threshold is <strong>0.5</strong>:
<ul>
<li>Probability of <strong>0.7</strong> → predicts class 1</li>
<li>Probability of <strong>0.2</strong> → predicts class 0</li>
</ul></li>
</ul>
</div>
</div>
</div>
<p>From looking at the confusion matrix again, we can see that there were only 38 samples in the testing set for which the model predicted class 1.</p>
<div id="511e0c83" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>confusion_matrix(y_test, y_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>array([[2721,   10],
       [  37,   28]])</code></pre>
</div>
</div>
<p>Equivalently, there were only 38 samples for which the model predicted a probability greater than 0.5.</p>
<p>If you’re wondering how this code works, the part within the parentheses is creating a boolean array, and summing that array converts each <code>True</code> to one and each <code>False</code> to zero.</p>
<div id="c3c0277e" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="bu">sum</span>(y_score <span class="op">&gt;</span> <span class="fl">0.5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>38</code></pre>
</div>
</div>
<p>With all of that in mind, we can infer two things from the fact that the AUC is high but the True Positive Rate is low:</p>
<ul>
<li>First, we know from the high AUC that the model is already doing a good job separating the classes.</li>
<li>Second, we know from the low True Positive Rate that the default decision threshold is not serving us well.</li>
</ul>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>What can we infer so far?</strong></p>
<ul>
<li><strong>High AUC:</strong> Model is already doing a good job separating the classes</li>
<li><strong>Low TPR:</strong> Default decision threshold is not serving us well</li>
</ul>
</div>
</div>
</div>
<p>To understand this second issue better, we’ll plot the ROC curve using the <code>plot_roc_curve</code> function, which was introduced in version 0.22. It uses an API similar to <code>plot_confusion_matrix</code>, in that we pass it the fitted model, <code>X_test</code>, and <code>y_test</code>, though the API has changed starting in scikit-learn 1.0.</p>
<p>So what are we looking at? The ROC curve is a plot of the True Positive Rate (on the y-axis) versus the False Positive Rate (on the x-axis) for all possible decision thresholds.</p>
<p>So for example, with the default decision threshold of 0.5, our True Positive Rate was 43%, and our False Positive Rate was nearly 0, which is represented by a single point on the curve.</p>
<p>We could move to another point on the curve simply by changing the decision threshold. For example, we could move to a point that has a True Positive Rate of about 90% and a False Positive Rate of about 10% by changing the threshold. To be clear, the threshold itself is not shown on this plot, rather the plot only shows the True Positive Rate and False Positive Rate pairs that result from all possible thresholds.</p>
<p>One other thing I want to note about this plot is that the Area Under the Curve is literally the percentage of the plot that is underneath the curve. So because the AUC is 0.93, we know that 93% of this plot is underneath this curve. If we can increase the AUC, that means we are moving the curve further into the upper left corner, which means that higher True Positive Rates and lower False Positive Rates will be available to us.</p>
<div id="4dfa15f4" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> plot_roc_curve</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>disp <span class="op">=</span> plot_roc_curve(logreg, X_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ch18_files/figure-html/cell-24-output-1.png" width="589" height="429" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>Interpreting the ROC curve:</strong></p>
<ul>
<li>Plot of the TPR vs FPR for all possible decision thresholds</li>
<li>Move to another point on the curve by changing the threshold
<ul>
<li>Threshold is not shown on this plot</li>
</ul></li>
<li>AUC is the percentage of the plot underneath the curve</li>
</ul>
</div>
</div>
</div>
<p>Given what we’ve learned so far, I want to chart our path forward. In lesson 18.7, we’re going to try to improve the AUC of our model. Then in lesson 18.8, we’re going to explore alternative decision thresholds in order to balance the True Positive Rate and the False Positive Rate to our liking.</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>Next steps:</strong></p>
<ol type="1">
<li>Improve the model’s AUC</li>
<li>Explore alternative decision thresholds</li>
</ol>
</div>
</div>
</div>
</section>
<section id="cost-sensitive-learning" class="level2" data-number="18.7">
<h2 data-number="18.7" class="anchored" data-anchor-id="cost-sensitive-learning"><span class="header-section-number">18.7</span> Cost-sensitive learning</h2>
<p>Now that we know that our next step is to improve our model’s AUC, how do we actually do that? The good news is that we can use any technique I’ve covered in this book, such as hyperparameter tuning, feature selection, trying non-linear models, and so on. All of those techniques have the potential to improve the model’s AUC.</p>
<p>However in this lesson, I want to focus on one particular technique that we haven’t covered in this book that is particularly useful in cases of class imbalance. That technique is called cost-sensitive learning.</p>
<p>The insight behind cost-sensitive learning is that not all prediction errors have the same cost. This can refer to an actual dollar cost of one type of error versus another, or in our case, the real-world implications of a certain type of error.</p>
<p>When there’s severe class imbalance, it’s usually the case that False Negatives, in which positive samples are identified as negative, have a higher cost than False Positives, in which negative samples are identified as positive. This makes sense because the positive samples are rare occurrences, and thus we’re more interested in locating the positive samples than the negative samples. In simple terms, we would prefer a False Positive to a False Negative.</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>How to improve the model’s AUC?</strong></p>
<ul>
<li><strong>Any technique covered in this book:</strong>
<ul>
<li>Hyperparameter tuning</li>
<li>Feature selection</li>
<li>Trying non-linear models</li>
<li>Etc.</li>
</ul></li>
<li><strong>Cost-sensitive learning:</strong>
<ul>
<li>Particularly useful when there’s class imbalance</li>
<li>Insight: Not all prediction errors have the same “cost”</li>
<li>If positive samples are rare:
<ul>
<li><strong>False Negatives</strong> have a higher cost</li>
<li><strong>False Positives</strong> have a lower cost</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
</div>
<p>So how does cost-sensitive learning actually work? In scikit-learn, this is implemented using the <code>class_weight</code> parameter for some models, such as logistic regression and Random Forests.</p>
<p>By setting <code>class_weight</code> to <code>'balanced'</code>, scikit-learn will give more weight to the samples from the minority class than samples from the majority class. More specifically, the model is penalized more for making mistakes on the minority class (meaning False Negatives) than it is for making mistakes on the majority class (meaning False Positives). Because the model’s goal is to minimize the total cost, the model may show increased bias toward predicting the minority class.</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>How does cost-sensitive learning work?</strong></p>
<ul>
<li>Gives more weight to samples from the minority class (positive class)
<ul>
<li>Model is penalized more for False Negatives than False Positives</li>
</ul></li>
<li>Model’s goal is to minimize total cost
<ul>
<li>Model may be biased toward predicting the minority class</li>
</ul></li>
</ul>
</div>
</div>
</div>
<p>Let’s try this out by creating a logistic regression instance that uses <code>class_weight='balanced'</code>. This specifies a class weighting that is inversely proportional to the class frequencies in the input data, though you can specify custom weights for each class if you like.</p>
<div id="365c5378" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>logreg_cost <span class="op">=</span> LogisticRegression(solver<span class="op">=</span><span class="st">'liblinear'</span>,</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>                                 class_weight<span class="op">=</span><span class="st">'balanced'</span>, random_state<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We’ll fit our logistic regression model on the training set, and use the fitted model to make class predictions as well as predicted probabilities on the testing set. Then we’ll calculate the AUC, and it has increased from 0.93 to 0.94 simply by setting class weights.</p>
<p>Keep in mind that class weighting is not guaranteed to improve your AUC, and thus it should be tuned like any other parameter, as we’ll see in the next chapter.</p>
<div id="94ac0130" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>logreg_cost.fit(X_train, y_train)</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> logreg_cost.predict(X_test)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>y_score <span class="op">=</span> logreg_cost.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>roc_auc_score(y_test, y_score)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>0.9404163028476467</code></pre>
</div>
</div>
<p>Let’s take a look at the classification report to see how our rates have changed:</p>
<ul>
<li>The True Positive Rate, which was 43%, is up to 88%.</li>
<li>The True Negative Rate, which was nearly 100%, is down to 89%, which means that the False Positive Rate has increased from around 0% to 11%.</li>
</ul>
<p>I do want to point out that even though this model might match our priorities better, its accuracy is down from 98% to 89%. This illustrates how sometimes a useful classifier has a lower accuracy than null accuracy.</p>
<div id="3fb2e1d1" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

           0       1.00      0.89      0.94      2731
           1       0.16      0.88      0.27        65

    accuracy                           0.89      2796
   macro avg       0.58      0.88      0.61      2796
weighted avg       0.98      0.89      0.93      2796
</code></pre>
</div>
</div>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>Changes due to cost-sensitive learning:</strong></p>
<ul>
<li><strong>TPR:</strong> 0.43 → 0.88</li>
<li><strong>FPR:</strong> 0.00 → 0.11</li>
</ul>
</div>
</div>
</div>
</section>
<section id="sec-18-8" class="level2" data-number="18.8">
<h2 data-number="18.8" class="anchored" data-anchor-id="sec-18-8"><span class="header-section-number">18.8</span> Tuning the decision threshold</h2>
<p>At this point, we could continue to tune various aspects of our model to increase the AUC, but instead we’re just going to move on to tuning the decision threshold.</p>
<p>Let’s take a look at the ROC curve for our class-weighted logistic regression model. Using the default threshold of 0.5, the model achieved a True Positive Rate of 88% and a False Positive Rate of 11%, which is represented by a single point on the curve. If we want to move somewhere else on this curve, in order to better match our priorities, we simply change the threshold.</p>
<div id="fa5f96e4" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>disp <span class="op">=</span> plot_roc_curve(logreg_cost, X_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ch18_files/figure-html/cell-28-output-1.png" width="589" height="429" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Before tuning the threshold, it’s useful to examine the confusion matrix. This is our current confusion matrix, which results from the default threshold of 0.5. You might notice that there are a lot more True Positives and False Positives than before.</p>
<div id="6989fbe4" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>confusion_matrix(y_test, y_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>array([[2436,  295],
       [   8,   57]])</code></pre>
</div>
</div>
<p>More specifically, the model is predicting the positive class 352 times, whereas previously it predicted the positive class only 38 times.</p>
<div id="3819d5f9" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="bu">sum</span>(y_score <span class="op">&gt;</span> <span class="fl">0.5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>352</code></pre>
</div>
</div>
<p>Let’s pretend that we’re still uncomfortable with having 8 False Negatives, and thus we want to reduce those even further. By decreasing the threshold to 0.25, we find out that the model will predict the positive class 870 times.</p>
<div id="7862aec6" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="bu">sum</span>(y_score <span class="op">&gt;</span> <span class="fl">0.25</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>870</code></pre>
</div>
</div>
<p>The boolean array created by this condition can be converted to class predictions simply by multiplying it by 1.</p>
<div id="c9bf1bb7" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>(y_score <span class="op">&gt;</span> <span class="fl">0.25</span>) <span class="op">*</span> <span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>array([0, 0, 0, ..., 0, 1, 0])</code></pre>
</div>
</div>
<p>And in fact, the boolean array can be passed directly to the confusion matrix function, and it will do the conversion automatically.</p>
<p>Thus we can see that by decreasing the threshold to 0.25, the number of False Negatives has been reduced from 8 to 4, but the number of False Positives has increased from 295 to 809. More generally, decreasing the threshold moves samples from the left column of the confusion matrix to the right column.</p>
<div id="e2379f7c" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>confusion_matrix(y_test, y_score <span class="op">&gt;</span> <span class="fl">0.25</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>array([[1922,  809],
       [   4,   61]])</code></pre>
</div>
</div>
<p>Looking at the classification report, the True Positive Rate has increased to 94%, but the False Positive Rate has increased to 30%. That moves us to a new spot on the ROC curve.</p>
<div id="9390497d" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_score <span class="op">&gt;</span> <span class="fl">0.25</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

           0       1.00      0.70      0.83      2731
           1       0.07      0.94      0.13        65

    accuracy                           0.71      2796
   macro avg       0.53      0.82      0.48      2796
weighted avg       0.98      0.71      0.81      2796
</code></pre>
</div>
</div>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>Changes due to decreasing the threshold:</strong></p>
<ul>
<li><strong>TPR:</strong> 0.88 → 0.94</li>
<li><strong>FPR:</strong> 0.11 → 0.30</li>
</ul>
</div>
</div>
</div>
<p>Alternatively, let’s pretend that we actually think the original threshold resulted in too many False Positives. In that case, we could increase the threshold to 0.75, which moves samples from the right column to the left column.</p>
<div id="afbc24f9" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>confusion_matrix(y_test, y_score <span class="op">&gt;</span> <span class="fl">0.75</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>array([[2632,   99],
       [  15,   50]])</code></pre>
</div>
</div>
<p>We can see from the classification report that the True Positive Rate has decreased to 77%, but the False Positive Rate has decreased to 4%. Again, that moves us to a new spot on the ROC curve.</p>
<div id="89725c09" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_score <span class="op">&gt;</span> <span class="fl">0.75</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

           0       0.99      0.96      0.98      2731
           1       0.34      0.77      0.47        65

    accuracy                           0.96      2796
   macro avg       0.66      0.87      0.72      2796
weighted avg       0.98      0.96      0.97      2796
</code></pre>
</div>
</div>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>Changes due to increasing the threshold:</strong></p>
<ul>
<li><strong>TPR:</strong> 0.88 → 0.77</li>
<li><strong>FPR:</strong> 0.11 → 0.04</li>
</ul>
</div>
</div>
</div>
<p>Keep in mind that as we change the threshold, it’s not actually changing the model itself. Instead, changing the threshold is just a way to make tradeoffs between two different types of errors, namely False Positives and False Negatives.</p>
<p>And to be clear, there is no correct threshold that we are trying to find. Instead, the threshold you should choose is the one that best matches your priorities. A method does exist for finding the point on the ROC curve that is closest to the upper left corner and calling that the correct threshold, but again, that threshold is only useful if it matches your priorities.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/mlbook\.dataschool\.io");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
            // default icon
            link.classList.add("external");
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./ch17.html" class="pagination-link" aria-label="High-cardinality categorical features">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">High-cardinality categorical features</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./ch19.html" class="pagination-link" aria-label="Class imbalance walkthrough">
        <span class="nav-page-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Class imbalance walkthrough</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2025, Kevin Markham. All Rights Reserved.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>